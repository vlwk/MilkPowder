{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA, TAGS & QUERIES\n",
    "Everything from the folder currently, with unfinished code for queries (near the end).\n",
    "\n",
    "Tags in `coldstorage4.csv` have yet to be modified as well.\n",
    "\n",
    "Always run *1) Imports* *2) Constants & Variable Initialisation* and *3) Helper Functions* before running anything else.\n",
    "\n",
    "Remember to document your code :)\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants & Variable Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://coldstorage.com.sg/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(url):\n",
    "    # Outputs the formatted html of a webpage parsed with lxml-parser\n",
    "    html = urlopen(url)\n",
    "    content = html.read()\n",
    "    return BeautifulSoup(content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping\n",
    "from https://coldstorage.com.sg/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining list of URLs to scrape\n",
    "\n",
    "This data is written onto `children.csv`. **If the folder already contains this file, you don't need to run this code.**\n",
    "\n",
    "For example, if one of the websites is https://coldstorage.com.sg/fruits-vegetables/fresh-fruits/apples-pears, the corresponding entry in the csv is `fruits-vegetables/fresh-fruits/apples-pears`.\n",
    "\n",
    "Note: Only items with **no deeper subcategories** are considered. For example, https://coldstorage.com.sg/fruits-vegetables is not an entry in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = []\n",
    "children = []\n",
    "categories = {}\n",
    "\n",
    "def dfs(node):\n",
    "    url = BASE_URL + node\n",
    "    if node in visited:\n",
    "        return\n",
    "    visited.append(node)\n",
    "    content = read(url)\n",
    "    print(\"processing: \" + node)\n",
    "    sub_categories = content.find_all('a', {\"class\": \"subcat_catalog\"})\n",
    "    if len(sub_categories) == 0:\n",
    "        children.append(node)\n",
    "        print(\"appended: \" + node)\n",
    "        return\n",
    "    for x in sub_categories:\n",
    "        nd = x['href'][1:]\n",
    "        dfs(nd)\n",
    "\n",
    "file = open(\"children.csv\", \"w\")\n",
    "\n",
    "content = read(BASE_URL)\n",
    "tmp = content.find_all(\"li\", {\"class\": \"col-sm-6 col-md-3 menu-promo\"})\n",
    "for i in tmp[:2]:\n",
    "    j = i.find_all('a')\n",
    "    for k in j:\n",
    "        categories[k['href'][1:]] = k.string.strip()\n",
    "\n",
    "for x in categories:\n",
    "    dfs(x)\n",
    "\n",
    "for x in children:\n",
    "    file.write(x + \"\\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual scraping\n",
    "\n",
    "*We use BeautifulSoup to navigate the html. Documentation at https://www.crummy.com/software/BeautifulSoup/bs4/doc/*\n",
    "\n",
    "Using the URLs in `children.csv`, data is extracted from the webpage and written onto `coldstorage4.csv` (remember to change the version number if you re-run the code). This code includes the creation of tags for each item.\n",
    "\n",
    "**Pages:** Depending on the number of items each URL contains, there might be a few pages for a specific URL (eg: https://coldstorage.com.sg/food-pantry/condiments-dressings/herbs-spices-seasonings), as shown:\n",
    "\n",
    "![Pages](pagenumbers.png \"Pages\")\n",
    "\n",
    "We use `find_all('li', {\"class\": \"page\"})` to look for every page in a URL, then iterate through the list of pages.\n",
    "\n",
    "Every item on the webpage is wrapped in `<li class=\"col-xs-6 col-sm-4 col-md-3 col-lg-2 open-product-detail algolia-click\"></li>`. We use `find_all('li', {\"class\": \"col-xs-6 col-sm-4 col-md-3 col-lg-2 open-product-detail algolia-click\"})` to look for every item.\n",
    "\n",
    "Inside the `<li></li>` tags for each item `x`, we find relevant attributes as follows:\n",
    "___\n",
    "`a = x.find('a', {\"class\": \"search product-quick-view\"})`\n",
    "\n",
    "![search-product-quick-view](pic1.png \"search product-quick-view\")\n",
    "\n",
    "**Brand (WAITROSE):** `a['data-product-brand']`\n",
    "\n",
    "**Size (350G):** `a['data-product-size'][6:]` (`[6:]` is to remove `Size: ` from the text)\n",
    "___\n",
    "`b = x.find('a', {\"class\": \"product-link\"})`\n",
    "\n",
    "![product-link](pic2.png \"product-link\")\n",
    "\n",
    "**Name (Sea Salt Coarse Crystals 350g):** `b.text`\n",
    "\n",
    "**URL ( https://coldstorage.com.sg/sea-salt-coarse-crystals-016542 ):** `BASE_URL + b['href'][9:]`\n",
    "___\n",
    "`c = x.find_all('div', {\"class\": \"content_price\"})[0]`\n",
    "![content-price](pic3.png \"content-price\")\n",
    "\n",
    "**Price (3.85):** `d = c.find_all('div'); d[0].text`\n",
    "___\n",
    "`e = x.find_all('div', {\"class\":\"promo-wrapper\"})[0]`\n",
    "![promo-wrapper](pic4.png \"promo-wrapper\")\n",
    "\n",
    "**Promotion (13% off):** `f = e.find_all('span'); f[0].text`\n",
    "___\n",
    "We create an array `row = []` and append all the attributes to this array. Tags are added as a single element (string) to the array, with the following structure: `\"<tag1>,<tag2>,<tag3>\"`. We then use `writerow(row)` to add the row to the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"coldstorage5.csv\", \"w\")\n",
    "file.write(\"name,url,tree,brand,size,price,promotion,tags,\\n\")\n",
    "filez = csv.writer(file)\n",
    "\n",
    "with open(\"children.csv\", \"r\") as f:\n",
    "    cutez = csv.reader(f)\n",
    "    for j in cutez:\n",
    "        ct = read(BASE_URL + j[0])\n",
    "        pages = ct.find_all('li', {\"class\": \"page\"})\n",
    "        if len(pages) > 0: # check if there are multiple pages\n",
    "            # the code in if and else are basically the same except that the one in if is inside a \"for i in pages\"\n",
    "            for i in pages:\n",
    "                ctt = read(BASE_URL + i.find('a')['href'][1:])\n",
    "                pdt = ctt.find_all('li', {\"class\": \"col-xs-6 col-sm-4 col-md-3 col-lg-2 open-product-detail algolia-click\"})\n",
    "                for x in pdt:\n",
    "                    a = x.find('a', {\"class\": \"search product-quick-view\"})\n",
    "                    b = x.find('a', {\"class\": \"product-link\"})\n",
    "                    c = x.find_all('div', {\"class\": \"content_price\"})[0]\n",
    "                    d = c.find_all('div')\n",
    "                    e = x.find_all('div', {\"class\":\"promo-wrapper\"})[0]\n",
    "                    f = e.find_all('span')\n",
    "                    row = [] # array of attributes to add as row to csv\n",
    "                    row.append(b.text) # name\n",
    "                    row.append(BASE_URL + b['href'][9:]) # url\n",
    "                    row.append(j[0]) # tree (see children.csv)\n",
    "                    row.append(a['data-product-brand']) # brand\n",
    "                    row.append(a['data-product-size'][6:]) # size\n",
    "                    if len(d) > 0: # check if item has price label\n",
    "                        row.append(d[0].text)\n",
    "                    else:\n",
    "                        row.append(\"\")\n",
    "                    if len(f) > 0: # check if item has promotion\n",
    "                        row.append(f[0].text)\n",
    "                    else:\n",
    "                        row.append(\"\")\n",
    "                        \n",
    "                    arr = [] # list of tags, excluding duplicates (currently taken from \"name\" and \"tree\")\n",
    "                    aa = b.text.rstrip().split(\" \")\n",
    "                    bb = j[0].rstrip().split(\"/\")\n",
    "                    for cc in bb:\n",
    "                        dd = cc.split('-')\n",
    "                        for i in dd:\n",
    "                            if i not in arr:\n",
    "                                arr.append(i)\n",
    "                    for i in aa:\n",
    "                        if i not in arr:\n",
    "                            arr.append(i)\n",
    "                    foo = \"\" # the string containing the tags\n",
    "                    for i in arr:\n",
    "                        foo += i\n",
    "                        foo += \",\"\n",
    "                    foo = foo[:len(foo)-1]\n",
    "                    print(foo)\n",
    "                    row.append(foo)\n",
    "                    print(row)\n",
    "                    filez.writerow(row)\n",
    "        else:\n",
    "            pdt = ct.find_all('li', {\"class\": \"col-xs-6 col-sm-4 col-md-3 col-lg-2 open-product-detail algolia-click\"})\n",
    "            for x in pdt:\n",
    "                a = x.find('a', {\"class\": \"search product-quick-view\"})\n",
    "                b = x.find('a', {\"class\": \"product-link\"})\n",
    "                c = x.find_all('div', {\"class\": \"content_price\"})[0]\n",
    "                d = c.find_all('div')\n",
    "                e = x.find_all('div', {\"class\":\"promo-wrapper\"})[0]\n",
    "                f = e.find_all('span')\n",
    "                row = []\n",
    "                row.append(b.text)\n",
    "                row.append(BASE_URL + b['href'][9:])\n",
    "                row.append(j[0])\n",
    "                row.append(a['data-product-brand'])\n",
    "                row.append(a['data-product-size'][6:])\n",
    "                if len(d) > 0:\n",
    "                    row.append(d[0].text)\n",
    "                else:\n",
    "                    row.append(\"\")\n",
    "                if len(f) > 0:\n",
    "                    row.append(f[0].text)\n",
    "                else:\n",
    "                    row.append(\"\")\n",
    "                arr = []\n",
    "                aa = b.text.rstrip().split(\" \")\n",
    "                bb = j[0].rstrip().split(\"/\")\n",
    "                for cc in bb:\n",
    "                    dd = cc.split('-')\n",
    "                    for i in dd:\n",
    "                        if i not in arr:\n",
    "                            arr.append(i)\n",
    "                for i in aa:\n",
    "                    if i not in arr:\n",
    "                        arr.append(i)\n",
    "                foo = \"\"\n",
    "                for i in arr:\n",
    "                    foo += i\n",
    "                    foo += \",\"\n",
    "                foo = foo[:len(foo)-1]\n",
    "                print(foo)\n",
    "                row.append(foo)\n",
    "                print(row)\n",
    "                filez.writerow(row)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating list of items with tags\n",
    "\n",
    "For use in one of the app's .js files (`roc.js` in this folder). Output is at `plswork.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need to understand the stuff here - it's just putting the tags in a js file for Siyong\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "yay = \"\"\n",
    "\n",
    "with open(\"old-data-files/coldstorage2.csv\", \"r\") as f:\n",
    "    file = csv.reader(f)\n",
    "    for line in file:\n",
    "        if (cnt == 0):\n",
    "            cnt += 1\n",
    "            continue\n",
    "\n",
    "        itemName = line[0].rstrip()\n",
    "        iuid = cnt + 29\n",
    "        istock = random.randint(0,100)\n",
    "        shelfLocation = \"shelf\" + str(random.randint(1, 4))\n",
    "        shelfRow = random.randint(1, 4)\n",
    "        shelfColumn = random.randint(1, 10)\n",
    "        friendlyLocation = line[2].rstrip()\n",
    "        cnt += 1\n",
    "\n",
    "        arr = []\n",
    "        a = line[0].rstrip().split(\" \")\n",
    "        b = line[2].rstrip().split('/')\n",
    "        for c in b:\n",
    "            d = c.split('-')\n",
    "            for i in d:\n",
    "                if i not in arr:\n",
    "                    arr.append(i)\n",
    "        for i in a:\n",
    "            if i not in arr:\n",
    "                arr.append(i)\n",
    "        tags = \"[\"\n",
    "        for i in arr:\n",
    "            tags += (\"\\\"\" + i + \"\\\"\")\n",
    "            tags += \",\"\n",
    "        tags = tags[:len(tags)-1]\n",
    "\n",
    "        tags += \"]\"\n",
    "\n",
    "        sleep = \"{\"\n",
    "        sleep += (\"\\\"iuid\\\":\" + str(iuid) + \",\")\n",
    "        sleep += (\"\\\"istock\\\":\" + str(istock) + \",\")\n",
    "        sleep += (\"\\\"itemName\\\":\" + \"\\\"\" + itemName + \"\\\"\" + \",\")\n",
    "        sleep += (\"\\\"shelfLocation\\\":\" + \"\\\"\" + shelfLocation + \"\\\"\" + \",\")\n",
    "        sleep += (\"\\\"friendlyLocation\\\":\" + \"\\\"\" + friendlyLocation + \"\\\"\" + \",\")\n",
    "        sleep += (\"\\\"shelfRow\\\":\" + str(shelfRow) + \",\")\n",
    "        sleep += (\"\\\"shelfColumn\\\":\" + str(shelfColumn) + \",\")\n",
    "        sleep += (\"\\\"tags\\\":\" + tags)\n",
    "        sleep += \"},\\n\"\n",
    "        yay += sleep\n",
    "\n",
    "with open(\"plswork2.txt\", \"w\") as f:\n",
    "    f.write(yay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query_id, item_name):\n",
    "    \n",
    "    # query_id is the numerical id of the query type\n",
    "    # item_name is a string containing the name of the item\n",
    "    # The function returns a string containing the query\n",
    "    \n",
    "    if (query_id == 1):\n",
    "        return \"Where can I find \" + item_name + \"?\"\n",
    "    if (query_id == 2):\n",
    "        return \"Where can I get \" + item_name + \"?\"\n",
    "    if (query_id == 3):\n",
    "        return \"Can I find \" + item_name + \"?\"\n",
    "    if (query_id == 4):\n",
    "        return \"Can I get \" + item_name + \"?\"\n",
    "    if (query_id == 5):\n",
    "        return \"Is there \" + item_name + \"?\"\n",
    "    if (query_id == 6):\n",
    "        return \"Is \" + item_name + \" in stock?\"\n",
    "    if (query_id == 7):\n",
    "        return \"Is \"+ item_name + \" available?\"\n",
    "    if (query_id == 8):\n",
    "        return \"Where is the \" + item_name + \"?\"\n",
    "    if (query_id == 9):\n",
    "        return \"Do you know where the \" + item_name + \" is?\"\n",
    "    if (query_id == 10):\n",
    "        return \"Can you check whether there is \" + item_name + \"?\"\n",
    "    if (query_id == 11):\n",
    "        return \"Check whether there is \" + item_name + \".\"\n",
    "    if (query_id == 12):\n",
    "        return \"I'm looking for \" + item_name + \".\"\n",
    "    if (query_id == 13):\n",
    "        return \"What \" + item_name + \" are there?\"\n",
    "    if (query_id == 14):\n",
    "        return \"Where is the \" + item_name + \" section?\"\n",
    "\n",
    "def test():\n",
    "    a = int(input(\"Enter query type: \"))\n",
    "    b = str(input(\"Enter item name: \"))\n",
    "    print(\"Query: \" + query(a, b))\n",
    "    \n",
    "test()\n",
    "\n",
    "\n",
    "'''\n",
    "fyi i found a list of query types that we can use\n",
    "\n",
    "1. Where can I find xxx?\n",
    "2. Where can I get xxx?\n",
    "3. Can I find xxx?\n",
    "4. Can I get xxx?\n",
    "5. Is there xxx here?\n",
    "6. Is xxx in stock?\n",
    "7. Is xxx available? \n",
    "8. Do you know where xxx is?\n",
    "9. Where is the xxx?\n",
    "10. Can you check whether there is xxx?\n",
    "11. Check whether there is xxx.\n",
    "12. I’m looking for xxx\n",
    "13. (broad cat) What xxx (vegetables) are there?\n",
    "14. (broad cat) Where is the xxx section?\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
